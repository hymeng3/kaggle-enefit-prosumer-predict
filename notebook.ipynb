{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-03T00:36:23.303112Z","iopub.status.busy":"2024-01-03T00:36:23.301629Z","iopub.status.idle":"2024-01-03T00:36:23.667997Z","shell.execute_reply":"2024-01-03T00:36:23.666419Z","shell.execute_reply.started":"2024-01-03T00:36:23.303061Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T00:38:16.832710Z","iopub.status.busy":"2024-01-03T00:38:16.832341Z","iopub.status.idle":"2024-01-03T00:38:17.864727Z","shell.execute_reply":"2024-01-03T00:38:17.862500Z","shell.execute_reply.started":"2024-01-03T00:38:16.832677Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2018352 entries, 0 to 2018351\n","Data columns (total 15 columns):\n"," #   Column                 Dtype              \n","---  ------                 -----              \n"," 0   county                 int64              \n"," 1   is_business            int64              \n"," 2   product_type           int64              \n"," 3   target                 float64            \n"," 4   is_consumption         int64              \n"," 5   datetime               datetime64[ns, UTC]\n"," 6   data_block_id          int64              \n"," 7   row_id                 int64              \n"," 8   prediction_unit_id     int64              \n"," 9   hour                   int32              \n"," 10  euros_per_mwh          float64            \n"," 11  lowest_price_per_mwh   float64            \n"," 12  highest_price_per_mwh  float64            \n"," 13  eic_count              float64            \n"," 14  installed_capacity     float64            \n","dtypes: datetime64[ns, UTC](1), float64(6), int32(1), int64(7)\n","memory usage: 223.3 MB\n","None\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>county</th>\n","      <th>is_business</th>\n","      <th>product_type</th>\n","      <th>target</th>\n","      <th>is_consumption</th>\n","      <th>datetime</th>\n","      <th>data_block_id</th>\n","      <th>row_id</th>\n","      <th>prediction_unit_id</th>\n","      <th>hour</th>\n","      <th>euros_per_mwh</th>\n","      <th>lowest_price_per_mwh</th>\n","      <th>highest_price_per_mwh</th>\n","      <th>eic_count</th>\n","      <th>installed_capacity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.713</td>\n","      <td>0</td>\n","      <td>2021-09-01 00:00:00+00:00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>108.0</td>\n","      <td>952.89</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>96.590</td>\n","      <td>1</td>\n","      <td>2021-09-01 00:00:00+00:00</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>108.0</td>\n","      <td>952.89</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.000</td>\n","      <td>0</td>\n","      <td>2021-09-01 00:00:00+00:00</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>17.0</td>\n","      <td>166.40</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>17.314</td>\n","      <td>1</td>\n","      <td>2021-09-01 00:00:00+00:00</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>17.0</td>\n","      <td>166.40</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2.904</td>\n","      <td>0</td>\n","      <td>2021-09-01 00:00:00+00:00</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>688.0</td>\n","      <td>7207.88</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   county  is_business  product_type  target  is_consumption  \\\n","0       0            0             1   0.713               0   \n","1       0            0             1  96.590               1   \n","2       0            0             2   0.000               0   \n","3       0            0             2  17.314               1   \n","4       0            0             3   2.904               0   \n","\n","                   datetime  data_block_id  row_id  prediction_unit_id  hour  \\\n","0 2021-09-01 00:00:00+00:00              0       0                   0     0   \n","1 2021-09-01 00:00:00+00:00              0       1                   0     0   \n","2 2021-09-01 00:00:00+00:00              0       2                   1     0   \n","3 2021-09-01 00:00:00+00:00              0       3                   1     0   \n","4 2021-09-01 00:00:00+00:00              0       4                   2     0   \n","\n","   euros_per_mwh  lowest_price_per_mwh  highest_price_per_mwh  eic_count  \\\n","0            NaN                   NaN                    NaN      108.0   \n","1            NaN                   NaN                    NaN      108.0   \n","2            NaN                   NaN                    NaN       17.0   \n","3            NaN                   NaN                    NaN       17.0   \n","4            NaN                   NaN                    NaN      688.0   \n","\n","   installed_capacity  \n","0              952.89  \n","1              952.89  \n","2              166.40  \n","3              166.40  \n","4             7207.88  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('data/train.csv')\n","train['datetime'] = pd.to_datetime(train['datetime'], utc=True)\n","train['hour'] = train['datetime'].dt.hour\n","\n","# Join electricity prices with training target by data_block_id and hour of day\n","electricity = pd.read_csv('data/electricity_prices.csv')\n","electricity['forecast_date'] = pd.to_datetime(electricity['forecast_date'], utc=True)\n","electricity['hour'] = electricity['forecast_date'].dt.hour\n","dataset = train.merge(electricity[['euros_per_mwh', 'hour', 'data_block_id']], how='left', on=['hour', 'data_block_id'])\n","\n","# Join gas prices with training target by data_block_id\n","gas = pd.read_csv('data/gas_prices.csv')\n","dataset = dataset.merge(gas[['data_block_id', 'lowest_price_per_mwh', 'highest_price_per_mwh']], how='left', on='data_block_id')\n","\n","# Join client types by data_block_id\n","client = pd.read_csv('data/client.csv')\n","client['data_block_id'] -= 2 # Client data_block_id seems to be ahead by 2 for the same days\n","dataset = dataset.merge(client.drop(columns = ['date']), how='left', on=['data_block_id', 'county', 'is_business', 'product_type'])\n","\n","print(dataset.info())\n","\n","dataset.head()\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2783/3127724278.py:31: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n","  forecast_weather_datetime = forecast_weather.groupby([forecast_weather['datetime'].dt.to_period('h')])[list(forecast_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","/tmp/ipykernel_2783/3127724278.py:35: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n","  forecast_weather_datetime_county= forecast_weather.groupby(['county',forecast_weather['datetime'].dt.to_period('h')])[list(forecast_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","/tmp/ipykernel_2783/3127724278.py:49: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n","  historical_weather_datetime = historical_weather.groupby([historical_weather['datetime'].dt.to_period('h')])[list(historical_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","/tmp/ipykernel_2783/3127724278.py:53: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n","  historical_weather_datetime_county= historical_weather.groupby(['county',historical_weather['datetime'].dt.to_period('h')])[list(historical_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n"]},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 229125 entries, 0 to 229124\n","Data columns (total 17 columns):\n"," #   Column                  Non-Null Count   Dtype              \n","---  ------                  --------------   -----              \n"," 0   county                  229125 non-null  int64              \n"," 1   datetime                229125 non-null  datetime64[ns, UTC]\n"," 2   temperature             229125 non-null  float64            \n"," 3   dewpoint                229125 non-null  float64            \n"," 4   rain                    229125 non-null  float64            \n"," 5   snowfall                229125 non-null  float64            \n"," 6   surface_pressure        229125 non-null  float64            \n"," 7   cloudcover_total        229125 non-null  float64            \n"," 8   cloudcover_low          229125 non-null  float64            \n"," 9   cloudcover_mid          229125 non-null  float64            \n"," 10  cloudcover_high         229125 non-null  float64            \n"," 11  windspeed_10m           229125 non-null  float64            \n"," 12  winddirection_10m       229125 non-null  float64            \n"," 13  shortwave_radiation     229125 non-null  float64            \n"," 14  direct_solar_radiation  229125 non-null  float64            \n"," 15  diffuse_radiation       229125 non-null  float64            \n"," 16  data_block_id           229125 non-null  float64            \n","dtypes: datetime64[ns, UTC](1), float64(15), int64(1)\n","memory usage: 29.7 MB\n"]}],"source":["weather_map = pd.read_csv('input/weather_station_to_county_mapping.csv')\n","forecast_weather = pd.read_csv('data/forecast_weather.csv')\n","historical_weather = pd.read_csv('data/historical_weather.csv')\n","\n","\n","\n","# Round longitude and latitude to nearest decimal\n","weather_map[['latitude', 'longitude']] = weather_map[['latitude', 'longitude']].astype(float).round(1)\n","forecast_weather[['latitude', 'longitude']] = forecast_weather[['latitude', 'longitude']].astype(float).round(1)\n","historical_weather[['latitude', 'longitude']] = historical_weather[['latitude', 'longitude']].astype(float).round(1)\n","\n","# Join county id to weather forecast via longitude and latitude\n","forecast_weather = forecast_weather.merge(weather_map[['longitude', 'latitude', 'county']], how='left', on=['longitude', 'latitude'])\n","historical_weather = historical_weather.merge(weather_map[['longitude', 'latitude', 'county']], how='left', on=['longitude', 'latitude'])\n","\n","# Drop NaNs that come from stations without county mapping and missing entries in weather\n","forecast_weather.dropna(axis=0, inplace=True) \n","historical_weather.dropna(axis=0, inplace=True)\n","\n","\n","### Prepare forecast weather for join with training data by forecast_datetime\n","forecast_weather['county'] = forecast_weather['county'].astype('int64')\n","\n","# Dropping the columns we don't need\n","forecast_weather.drop(['origin_datetime', 'latitude','longitude', 'hours_ahead', 'data_block_id'], axis=1, inplace= True)\n","\n","forecast_weather.rename(columns={'forecast_datetime': 'datetime'}, inplace= True)\n","forecast_weather['datetime']= pd.to_datetime(forecast_weather['datetime'], utc= True)\n","\n","# Take the mean of forecasts within the same hour across all stations\n","forecast_weather_datetime = forecast_weather.groupby([forecast_weather['datetime'].dt.to_period('h')])[list(forecast_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","forecast_weather_datetime['datetime']= pd.to_datetime(forecast_weather_datetime['datetime'].dt.to_timestamp(), utc=True)\n","\n","# Take the mean of forecasts of stations within the same county\n","forecast_weather_datetime_county= forecast_weather.groupby(['county',forecast_weather['datetime'].dt.to_period('h')])[list(forecast_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","forecast_weather_datetime_county['datetime']= pd.to_datetime(\n","forecast_weather_datetime_county['datetime'].dt.to_timestamp(), utc=True)\n","\n","\n","### Prepare historical weather for join with training data by data_block_id and hour of day\n","historical_weather['county'] = historical_weather['county'].astype('int64')\n","\n","# Dropping the columns we don't need\n","historical_weather.drop(['latitude','longitude'], axis=1, inplace= True)\n","\n","historical_weather['datetime']= pd.to_datetime(historical_weather['datetime'], utc= True)\n","\n","# Take the mean of values within the same hour across all stations\n","historical_weather_datetime = historical_weather.groupby([historical_weather['datetime'].dt.to_period('h')])[list(historical_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","historical_weather_datetime['datetime']= pd.to_datetime(historical_weather_datetime['datetime'].dt.to_timestamp(), utc=True)\n","\n","# Take the mean of forecasts of stations within the same county\n","historical_weather_datetime_county= historical_weather.groupby(['county',historical_weather['datetime'].dt.to_period('h')])[list(historical_weather.drop(['county','datetime'], axis= 1).columns)].mean().reset_index()\n","historical_weather_datetime_county['datetime']= pd.to_datetime(\n","historical_weather_datetime_county['datetime'].dt.to_timestamp(), utc=True)\n","\n","historical_weather_datetime_county.info()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2018352 entries, 0 to 2018351\n","Data columns (total 41 columns):\n"," #   Column                             Dtype              \n","---  ------                             -----              \n"," 0   county                             int64              \n"," 1   is_business                        int64              \n"," 2   product_type                       int64              \n"," 3   target                             float64            \n"," 4   is_consumption                     int64              \n"," 5   datetime                           datetime64[ns, UTC]\n"," 6   data_block_id                      int64              \n"," 7   row_id                             int64              \n"," 8   prediction_unit_id                 int64              \n"," 9   hour                               int32              \n"," 10  euros_per_mwh                      float64            \n"," 11  lowest_price_per_mwh               float64            \n"," 12  highest_price_per_mwh              float64            \n"," 13  eic_count                          float64            \n"," 14  installed_capacity                 float64            \n"," 15  temperature_x                      float64            \n"," 16  dewpoint_x                         float64            \n"," 17  cloudcover_high_x                  float64            \n"," 18  cloudcover_low_x                   float64            \n"," 19  cloudcover_mid_x                   float64            \n"," 20  cloudcover_total_x                 float64            \n"," 21  10_metre_u_wind_component          float64            \n"," 22  10_metre_v_wind_component          float64            \n"," 23  direct_solar_radiation_x           float64            \n"," 24  surface_solar_radiation_downwards  float64            \n"," 25  snowfall_x                         float64            \n"," 26  total_precipitation                float64            \n"," 27  temperature_y                      float64            \n"," 28  dewpoint_y                         float64            \n"," 29  rain                               float64            \n"," 30  snowfall_y                         float64            \n"," 31  surface_pressure                   float64            \n"," 32  cloudcover_total_y                 float64            \n"," 33  cloudcover_low_y                   float64            \n"," 34  cloudcover_mid_y                   float64            \n"," 35  cloudcover_high_y                  float64            \n"," 36  windspeed_10m                      float64            \n"," 37  winddirection_10m                  float64            \n"," 38  shortwave_radiation                float64            \n"," 39  direct_solar_radiation_y           float64            \n"," 40  diffuse_radiation                  float64            \n","dtypes: datetime64[ns, UTC](1), float64(32), int32(1), int64(7)\n","memory usage: 623.7 MB\n"]}],"source":["# Join weather data with training target\n","dataset = dataset.merge(forecast_weather_datetime_county, how='left', on=['datetime', 'county'])\n","\n","historical_weather_datetime_county['hour']= historical_weather_datetime_county['datetime'].dt.hour\n","historical_weather_datetime_county.drop('datetime', axis= 1, inplace= True)\n","dataset = dataset.merge(historical_weather_datetime_county, how='left', on=['data_block_id', 'county', 'hour'])\n","\n","dataset.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7292407,"sourceId":57236,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
